{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "N.B. Based on an [OpenAI example notebook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb). [gptchem](https://github.com/kjappelbaum/gptchem) uses an outdated version of the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Union, List, Dict\n",
    "import pathlib as pl\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ai4chem.tokenizers import gpt_num_tokens_from_messages\n",
    "from ai4chem.data import Deep4ChemDataset, ChemFluorDataset, split_on_unique_smiles\n",
    "\n",
    "with open('/Users/azadoks/.zshrc.d/10_openai_bot.sh', 'r') as f:\n",
    "    api_key = f.read().split('=')[1].strip()\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_message(property_name: str) -> str:\n",
    "    return f\"You predict properties of molecules with high accuracy to assist chemists. You are to predict the {property_name} maximum wavelength in nanometers of the provided molecule when dissolved in the provided solvent.\"\n",
    "\n",
    "def get_user_message(row, representation: Union[str, List[str]]=\"smiles\") -> str:\n",
    "    def _get_molecule_line(row, representation: str) -> str:\n",
    "        return f\"Molecule {representation}: {row[f'chromophore_{representation}']}\"\n",
    "    def _get_solvent_line(row, representation: str) -> str:\n",
    "        return f\"Solvent {representation}: {row[f'solvent_{representation}']}\"\n",
    "\n",
    "    if isinstance(representation, str):\n",
    "        molecule_lines = _get_molecule_line(row, representation)\n",
    "        solvent_lines = _get_solvent_line(row, representation)\n",
    "    else:\n",
    "        molecule_lines = \"\\n\".join([_get_molecule_line(row, rep) for rep in representation])\n",
    "        solvent_lines = \"\\n\".join([_get_solvent_line(row, rep) for rep in representation])\n",
    "\n",
    "    return f'{molecule_lines}\\n\\n{solvent_lines}'\n",
    "\n",
    "def get_train_conversation(row, property_name: str, representation: Union[str, List[str]]=\"smiles\") -> Dict:\n",
    "    messages = []\n",
    "    messages.append({'role': 'system', 'content': get_system_message(property_name)})\n",
    "    messages.append({'role': 'user', 'content': get_user_message(row, representation)})\n",
    "    property_key = f'{property_name.lower()}_max'\n",
    "    messages.append({'role': 'assistant', 'content': f'{int(row[property_key]):3d} nm'})\n",
    "    return {'messages': messages}\n",
    "\n",
    "def get_test_conversation(row, property_name: str, representation: Union[str, List[str]]=\"smiles\") -> Dict:\n",
    "    messages = []\n",
    "    messages.append({'role': 'system', 'content': get_system_message(property_name)})\n",
    "    messages.append({'role': 'user', 'content': get_user_message(row, representation)})\n",
    "    property_key = f'{property_name.lower()}_max'\n",
    "    return {'messages': messages}, f'{int(row[property_key]):3d} nm'\n",
    "\n",
    "def get_prompt(row, property_name: str, representation: Union[str, List[str]]=\"smiles\") -> str:\n",
    "    return f\"What is the {property_name} maximum wavelength of {row[f'chromophore_{representation}']} dissolved in {row[f'solvent_{representation}']}?\"\n",
    "\n",
    "def get_completion(row, property_name: str) -> str:\n",
    "    property_key = f'{property_name.lower()}_max'\n",
    "    return f' {int(row[property_key]):3d} nm'\n",
    "\n",
    "def get_train_prompt_completion(row, property_name: str, representation: Union[str, List[str]]=\"smiles\") -> Dict:\n",
    "    return {\n",
    "        'prompt': get_prompt(row, property_name, representation),\n",
    "        'completion': get_completion(row, property_name)\n",
    "    }\n",
    "\n",
    "def get_inverse_prompt(row, property_name: str, representation: str=\"smiles\") -> str:\n",
    "    property_key = f'{property_name.lower()}_max'\n",
    "    return f\"What is a chromophore + solvent pair with an {property_name} maximum wavelength of {int(row[property_key]):3d} nm?\"\n",
    "\n",
    "def get_inverse_completion(row, representation: str=\"smiles\") -> str:\n",
    "    return f\"Molecule {representation}: {row[f'chromophore_{representation}']}$$$ Solvent {representation}: {row[f'solvent_{representation}']}$$$\"\n",
    "\n",
    "def get_inverse_prompt_completion(row, property_name: str, representation: str=\"smiles\") -> Dict:\n",
    "    return {\n",
    "        'prompt': get_inverse_prompt(row, property_name, representation),\n",
    "        'completion': get_inverse_completion(row, representation)\n",
    "    }\n",
    "\n",
    "def write_jsonl(data: list, filename: os.PathLike) -> None:\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "def count_tokens(data: List[Dict]) -> int:\n",
    "    return sum(\n",
    "        gpt_num_tokens_from_messages(row['messages'], model=\"gpt-3.5-turbo-0613\")\n",
    "        for row in data\n",
    "    )\n",
    "\n",
    "def make_completion_conversations(data: pd.DataFrame, property_name: str, direction: str, representation: Union[str, List[str]]=\"smiles\") -> List[Dict]:\n",
    "    if direction == 'forward':\n",
    "        return data.apply(lambda x: get_train_prompt_completion(x, property_name, representation), axis=1)\n",
    "    if direction == 'inverse':\n",
    "        return data.apply(lambda x: get_inverse_prompt_completion(x, property_name, representation), axis=1)\n",
    "    raise ValueError(f\"Invalid direction: {direction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemfluor_path = '../data/chemfluor/data.csv'\n",
    "deep4chem_path = '../data/deep4chem/data.csv'\n",
    "\n",
    "chemfluor = ChemFluorDataset(chemfluor_path, canonicalize_smiles=True)\n",
    "deep4chem = Deep4ChemDataset(deep4chem_path, canonicalize_smiles=True)\n",
    "\n",
    "combined_df = pd.concat([chemfluor.clean_data, deep4chem.clean_data], ignore_index=True).reset_index(drop=True)\n",
    "n_unique_smiles = len(combined_df['chromophore_smiles'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromophore_smiles: Cc1cc(=O)c2ccccc2o1 False\n",
      "solvent_smiles: CC#N True\n",
      "\n",
      "chromophore_smiles: Cc1ccc([N+](=O)[O-])cc1 False\n",
      "solvent_smiles: ClCCl True\n",
      "\n",
      "chromophore_smiles: O=Cc1ccc(C=Cc2ccccc2)cc1 False\n",
      "solvent_smiles: C1CCOC1 True\n",
      "\n",
      "chromophore_smiles: CCN(CC)C(=O)c1cccc2ccccc12 False\n",
      "solvent_smiles: CCOCC True\n",
      "\n",
      "chromophore_smiles: CC1=CC(=O)C=C2C(=O)C=C(C#N)C=CC12 False\n",
      "solvent_smiles: CCO True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "gpt_gen = [\n",
    "    {\n",
    "        'chromophore_smiles': 'CC1=CC(=O)C2=C(O1)C=CC=C2',\n",
    "        'solvent_smiles': 'CC#N'\n",
    "    },\n",
    "    {\n",
    "        'chromophore_smiles': 'CC1=CC=C(C=C1)[N+](=O)[O-]',\n",
    "        'solvent_smiles': 'ClCCl'\n",
    "    },\n",
    "    {\n",
    "        'chromophore_smiles': 'C1=CC(=CC=C1C=CC2=CC=CC=C2)C=O',\n",
    "        'solvent_smiles': 'C1CCOC1'\n",
    "    },\n",
    "    {\n",
    "        'chromophore_smiles': 'CCN(CC)C(=O)C1=CC=CC2=C1C=CC=C2',\n",
    "        'solvent_smiles': 'CCOCC'\n",
    "    },\n",
    "    {\n",
    "        'chromophore_smiles': 'CC1=CC(=O)C=C2C1C=CC(=CC2=O)C#N',\n",
    "        'solvent_smiles': 'OCC'\n",
    "    },\n",
    "]\n",
    "\n",
    "for (i, pair) in enumerate(gpt_gen):\n",
    "    gpt_gen[i] = {k: Chem.MolToSmiles(Chem.MolFromSmiles(v)) for k, v in pair.items()}\n",
    "\n",
    "for pair in gpt_gen:\n",
    "    for (k, v) in pair.items():\n",
    "        print(f'{k}: {v} {v in combined_df[k].values}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 (2460, 4) (0, 4) (16899, 4)\n",
      "Training file ID: file-UxONBSdgKf5SefPiUZnwk5s7\n",
      "Job ID: ftjob-MxXjF6V2LFHxrt6Wvuo3TuDS\n",
      "Status: validating_files\n",
      "Training file ID: file-7l0p7LkuWxApdJkR7bZ69OmE\n",
      "Job ID: ftjob-NWjQY5JkLod5upQuXVINcaaZ\n",
      "Status: validating_files\n",
      "Training file ID: file-G4yh7TXVGKhKVRQJcMSsQotb\n",
      "Job ID: ftjob-f6VT5IebaJQCO6ZyayXaCT1x\n",
      "Status: validating_files\n",
      "Training file ID: file-WcDg8mzKb3L6w7HcTk0Fa1Vc\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': \"This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'babbage-002'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     val_file_id \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mNOT_GIVEN\n\u001b[0;32m---> 49\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbabbage-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m job_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/resources/fine_tuning/jobs/jobs.py:128\u001b[0m, in \u001b[0;36mJobs.create\u001b[0;34m(self, model, training_file, hyperparameters, integrations, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FineTuningJob:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    a given dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegrations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai4chem/lib/python3.11/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': \"This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'babbage-002'.\", 'type': 'invalid_request_error', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# n_trains = (10, 50, 100, 500, 1000)\n",
    "n_trains = (1000, )\n",
    "seed = 9997\n",
    "directions = ('forward', 'inverse')\n",
    "property_names = ('emission', 'absorption')\n",
    "representation = 'smiles'\n",
    "model_name = 'babbage-002'\n",
    "\n",
    "for n_train in n_trains:\n",
    "    splits = (n_train, 0, n_unique_smiles - n_train)\n",
    "    train_df, val_df, test_df = split_on_unique_smiles(combined_df, splits, seed=seed)\n",
    "    print(n_train, train_df.shape, val_df.shape, test_df.shape)\n",
    "    for property_name in property_names:\n",
    "        for direction in directions:\n",
    "            # experiment_name = f'{n_train:d}-{representation.lower()[:3]}-{property_name[:3].lower()}-{direction[:1].lower()}{model_name[:1].lower()}{datetime.now().strftime(\"%d%H%M\")}'\n",
    "            experiment_name = f'{n_train:d}{property_name[:1].lower()}{direction[:1].lower()}{model_name[:1].lower()}{datetime.now().strftime(\"%d%H%M\")}'\n",
    "            experiment_data_path = pl.Path(f'../data/{experiment_name}')\n",
    "            experiment_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "            train_convos = make_completion_conversations(train_df, property_name, direction, representation)\n",
    "            val_convos = make_completion_conversations(val_df, property_name, direction, representation)\n",
    "            test_convos = make_completion_conversations(test_df, property_name, direction, representation)\n",
    "\n",
    "            train_filename = str(experiment_data_path / \"train.jsonl\")\n",
    "            write_jsonl(train_convos, train_filename)\n",
    "            if len(val_convos) > 0:\n",
    "                val_filename = str(experiment_data_path / \"validate.jsonl\")\n",
    "                write_jsonl(val_convos, val_filename)\n",
    "            test_filename = str(experiment_data_path / \"test.jsonl\")\n",
    "            write_jsonl(test_convos, test_filename)\n",
    "\n",
    "            with open(train_filename, \"rb\") as train_fd:\n",
    "                training_response = client.files.create(\n",
    "                    file=train_fd, purpose=\"fine-tune\"\n",
    "                )\n",
    "            train_file_id = training_response.id\n",
    "            print(\"Training file ID:\", train_file_id)\n",
    "\n",
    "            if len(val_convos) > 0:\n",
    "                with open(val_filename, \"rb\") as val_fd:\n",
    "                    val_response = client.files.create(\n",
    "                        file=val_fd, purpose=\"fine-tune\"\n",
    "                    )\n",
    "                val_file_id = val_response.id\n",
    "                print(\"Validation file ID:\", val_file_id)\n",
    "            else:\n",
    "                val_file_id = openai.NOT_GIVEN\n",
    "\n",
    "            response = client.fine_tuning.jobs.create(\n",
    "                training_file=train_file_id,\n",
    "                validation_file=val_file_id,\n",
    "                model=\"babbage-002\",\n",
    "                suffix=experiment_name,\n",
    "            )\n",
    "\n",
    "            job_id = response.id\n",
    "\n",
    "            print(\"Job ID:\", response.id)\n",
    "            print(\"Status:\", response.status)\n",
    "\n",
    "            with open(experiment_data_path / \"job_id.txt\", \"w\") as f:\n",
    "                f.write(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = 'inverse'\n",
    "property_name = \"absorption\"\n",
    "representation = \"SMILES\"\n",
    "model_name = \"babbage-002\"\n",
    "\n",
    "experiment_name = f'{representation.lower()[:3]}-{property_name[:3].lower()}-{direction[:1].lower()}{model_name[:1].lower()}{datetime.now().strftime(\"%d%H%M\")}'\n",
    "\n",
    "if direction == 'forward':\n",
    "    if 'gpt' in model_name:\n",
    "        train_data = train_df.apply(lambda row: get_train_conversation(row, property_name, representation), axis=1).tolist()\n",
    "        validate_data = validate_df.apply(lambda row: get_train_conversation(row, property_name, representation), axis=1).tolist()\n",
    "        test_data = test_df.apply(lambda row: get_train_conversation(row, property_name, representation), axis=1).tolist()\n",
    "    elif 'babbage' or 'davinci' in model_name:\n",
    "        train_data = train_df.apply(lambda row: get_train_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "        validate_data = validate_df.apply(lambda row: get_train_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "        test_data = test_df.apply(lambda row: get_train_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "elif direction == 'inverse':\n",
    "    if 'babbage' or 'davinci' in model_name:\n",
    "        train_data = train_df.apply(lambda row: get_inverse_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "        validate_data = validate_df.apply(lambda row: get_inverse_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "        test_data = test_df.apply(lambda row: get_inverse_prompt_completion(row, property_name, representation), axis=1).tolist()\n",
    "\n",
    "print(experiment_name)\n",
    "for conversation in train_data[:5]:\n",
    "    print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data_path = pl.Path(f'../data/{experiment_name}')\n",
    "experiment_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "train_filename = str(experiment_data_path / \"train.jsonl\")\n",
    "write_jsonl(train_data, train_filename)\n",
    "\n",
    "validate_filename = str(experiment_data_path / \"validate.jsonl\")\n",
    "write_jsonl(validate_data, validate_filename)\n",
    "\n",
    "test_filename = str(experiment_data_path / \"test.jsonl\")\n",
    "write_jsonl(test_data, test_filename)\n",
    "\n",
    "!head -n 5 $train_filename\n",
    "!wc -l $train_filename\n",
    "!wc -l $validate_filename\n",
    "!wc -l $test_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_filename, \"rb\") as train_fd:\n",
    "    training_response = client.files.create(\n",
    "        file=train_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "train_file_id = training_response.id\n",
    "\n",
    "with open(validate_filename, \"rb\") as validate_fd:\n",
    "    validate_response = client.files.create(\n",
    "        file=validate_fd, purpose=\"fine-tune\"\n",
    "    )\n",
    "validate_file_id = validate_response.id\n",
    "\n",
    "print(experiment_name)\n",
    "print(\"Training file ID:\", train_file_id)\n",
    "print(\"Validation file ID:\", validate_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file_id,\n",
    "    validation_file=validate_file_id,\n",
    "    model=\"babbage-002\",\n",
    "    suffix=experiment_name,\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "\n",
    "with open(experiment_data_path / \"job_id.txt\", \"w\") as f:\n",
    "    f.write(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
